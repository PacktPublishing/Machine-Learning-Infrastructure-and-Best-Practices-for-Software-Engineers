{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0HtO3l7tTlr"
   },
   "source": [
    "# Training an Autoencoder model\n",
    "\n",
    "In this demo, we go through the process of training an autoencoder model. We use a basic architecture for PyTorch.\n",
    "\n",
    "As the input data, we use the Fashion MNIST dataset, as it demonstrates the possibilities of autoencoders without the hassle of finding new data.\n",
    "\n",
    "If you would like to explore more datasets to train your autoencoder, please take a look at the torchvision library here: https://pytorch.org/vision/stable/datasets.html\n",
    "\n",
    "This tutorial is based on the tutorial from: https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/\n",
    "\n",
    "With the following modifications:\n",
    "* changed the dataset to Fashion MNIST\n",
    "* added visualization of the autoencoder\n",
    "* minor bug-fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaSt3RhzCZS4"
   },
   "outputs": [],
   "source": [
    "# installing the visualization module that\n",
    "# we will later use for drawing the autoencoder architecture\n",
    "!pip install -q torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnP3PUOOv0b5"
   },
   "outputs": [],
   "source": [
    "# imports needed for the autoencoder itself\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# imports needed for the visualizaation of the network\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPsOkkBSENAk"
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99Ef-EidECK1",
    "outputId": "12524990-2e74-476b-a83b-3e19989e86c3"
   },
   "outputs": [],
   "source": [
    "# Transforms images to a PyTorch Tensor\n",
    "tensor_transform = transforms.ToTensor()\n",
    "\n",
    "# Download the MNIST Dataset\n",
    "dataset = datasets.FashionMNIST(root = \"./data\",\n",
    "                         train = True,\n",
    "                         download = True,\n",
    "                         transform = tensor_transform)\n",
    "\n",
    "# DataLoader is used to load the dataset\n",
    "# for training\n",
    "loader = torch.utils.data.DataLoader(dataset = dataset,\n",
    "                                     batch_size = 32,\n",
    "                                     shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZIzSRl2v6VF"
   },
   "outputs": [],
   "source": [
    "# Creating a PyTorch class\n",
    "# 28*28 ==> 9 ==> 28*28\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Building an linear encoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # 784 ==> 9\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28 * 28, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 9)\n",
    "        )\n",
    "\n",
    "        # Building an linear decoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # The Sigmoid activation function\n",
    "        # outputs the value between 0 and 1\n",
    "        # 9 ==> 784\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(9, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 28 * 28),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvLHnK8AwAPQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Model Initialization\n",
    "model = AE()\n",
    "\n",
    "# Validation using MSE Loss function\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "# Using an Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-1,\n",
    "                             weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohWMneYYwDW-"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "outputs = []\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    for (image, _) in loader:\n",
    "\n",
    "      # Reshaping the image to (-1, 784)\n",
    "      image = image.reshape(-1, 28*28)\n",
    "\n",
    "      # Output of Autoencoder\n",
    "      reconstructed = model(image)\n",
    "\n",
    "      # Calculating the loss function\n",
    "      loss = loss_function(reconstructed, image)\n",
    "\n",
    "      # The gradients are set to zero,\n",
    "      # the gradient is computed and stored.\n",
    "      # .step() performs parameter update\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Storing the losses in a list for plotting\n",
    "      losses.append(loss)\n",
    "    outputs.append((epochs, image, reconstructed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "wO5UWxo7xbse",
    "outputId": "6119c585-81a1-43ed-b2fc-4a562cd8e164"
   },
   "outputs": [],
   "source": [
    "# Defining the Plot Style\n",
    "plt.style.use('seaborn')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Convert the list to a PyTorch tensor\n",
    "losses_tensor = torch.tensor(losses)\n",
    "\n",
    "# Plotting the last 100 values\n",
    "plt.plot(losses_tensor.detach().numpy()[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "ROwg2ahOwShR",
    "outputId": "528e31fe-deae-4006-caf2-74357ed70374"
   },
   "outputs": [],
   "source": [
    "for i, item in enumerate(image):\n",
    "\n",
    "  # Reshape the array for plotting\n",
    "  item = item.reshape(-1, 28, 28)\n",
    "  plt.imshow(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X3KqhhBtzHiB",
    "outputId": "7a5a5051-578b-4b1a-8a03-c1a59a154b90"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSoLN6YBzzjS",
    "outputId": "0ac0dad3-ee89-4928-f7db-4d48961619ee"
   },
   "outputs": [],
   "source": [
    "!pip install torchviz\n",
    "from torchviz import make_dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFkCz_Ai0YD9"
   },
   "outputs": [],
   "source": [
    "# batch = next(iter(dataloader_train))\n",
    "yhat = model(image[0]) # Give dummy batch to forward()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ceDK-2CI0ist",
    "outputId": "06a2e81e-b372-427a-9a32-6cab7ccf9aa2"
   },
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(yhat,\n",
    "         params=dict(list(model.named_parameters())),\n",
    "         show_attrs=True,\n",
    "         show_saved=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "j35zSUzu2D8i",
    "outputId": "f9318d83-6c9a-4af3-d481-2fdcb0ed0ec7"
   },
   "outputs": [],
   "source": [
    "make_dot(yhat).render(format='png')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
