{"cells":[{"cell_type":"markdown","metadata":{"id":"s_q15InjLhCs"},"source":["# Training models for numerical data\n","\n","This workbook illustrates how we can train a machine learning model for numerical data, with the focus on the visualization of the model. \n","\n","We train a CART decision tree model since we can explore how the model recognized the pattern in the data and how it could re-create it. "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":767,"status":"ok","timestamp":1686036187648,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"kgt7n_-bMK8x"},"outputs":[],"source":["# read the file with data using openpyxl\n","import pandas as pd\n","\n","# we read the data from the excel file, \n","# which is the defect data from the ant 1.3 system\n","dfDataAnt13 = pd.read_excel('./chapter_6_dataset_numerical.xlsx', \n","                            sheet_name='ant_1_3',\n","                            index_col=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":325,"status":"ok","timestamp":1686036190278,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"824XQ9xSNBW8","outputId":"421ce0b6-7964-4ad2-e7b7-4c79beade047"},"outputs":[],"source":["dfDataAnt13.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":348,"status":"ok","timestamp":1686036193228,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"Sbo7eXQlMWfe"},"outputs":[],"source":["# prepare the dataset\n","import sklearn.model_selection\n","\n","X = dfDataAnt13.drop(['Defect'], axis=1)\n","y = dfDataAnt13.Defect\n","\n","X_train, X_test, y_train, y_test = \\\n","        sklearn.model_selection.train_test_split(X, y, random_state=42, train_size=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":257,"status":"ok","timestamp":1686036198847,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"L_9rZStzkiGc"},"outputs":[],"source":["# now that we have the data prepared\n","# we import the decision tree classifier and train it\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# first we create an empty classifier\n","decisionTreeModel = DecisionTreeClassifier()\n","\n","# then we train the classifier\n","decisionTreeModel.fit(X_train, y_train)\n","\n","# and we test it for the test set\n","y_pred_cart = decisionTreeModel.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1686036201120,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"tIPbflpUlGtq","outputId":"92c26d9e-e056-442a-99de-8b5451c905a7"},"outputs":[],"source":["# now, let's evaluate the code\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","\n","print(f'Accuracy: {accuracy_score(y_test, y_pred_cart):.2f}')\n","print(f'Precision: {precision_score(y_test, y_pred_cart, average=\"weighted\"):.2f}, Recall: {recall_score(y_test, y_pred_cart, average=\"weighted\"):.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1686036204910,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"JYbBnwfzlUkt","outputId":"bbc18cf1-7ca0-4559-d8ea-ddd60623edde"},"outputs":[],"source":["from sklearn.tree import export_text\n","\n","tree_rules = export_text(decisionTreeModel, feature_names=list(X_train.columns))\n","\n","print(tree_rules)"]},{"cell_type":"markdown","metadata":{"id":"gJ9_l59erSPv"},"source":["# Counter example\n","\n","In this counter example, we use data from the same dataset, but for a different module. Let's see how the performance of the model differs based on the data. "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1564,"status":"ok","timestamp":1686044745904,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"h2JFXhJJrcQx"},"outputs":[],"source":["# read the file with data using openpyxl\n","import pandas as pd\n","\n","# we read the data from the excel file, \n","# which is the defect data from the ant 1.3 system\n","dfDataCamel12 = pd.read_excel('./chapter_6_dataset_numerical.xlsx', \n","                            sheet_name='camel_1_2',\n","                            index_col=0)\n","\n","# prepare the dataset\n","import sklearn.model_selection\n","\n","X = dfDataCamel12.drop(['Defect'], axis=1)\n","y = dfDataCamel12.Defect\n","\n","X_train, X_test, y_train, y_test = \\\n","        sklearn.model_selection.train_test_split(X, y, random_state=42, train_size=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":347,"status":"ok","timestamp":1686037814955,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"I0MQJ0-zrs9r"},"outputs":[],"source":["# now that we have the data prepared\n","# we import the decision tree classifier and train it\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# first we create an empty classifier\n","decisionTreeModelCamel = DecisionTreeClassifier()\n","\n","# then we train the classifier\n","decisionTreeModelCamel.fit(X_train, y_train)\n","\n","# and we test it for the test set\n","y_pred_cart_camel = decisionTreeModel.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1686037830241,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"fT3A1FpMrxd3","outputId":"f6945b38-0385-4486-962a-1e310cb50730"},"outputs":[],"source":["# now, let's evaluate the code\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","\n","print(f'Accuracy: {accuracy_score(y_test, y_pred_cart_camel):.2f}')\n","print(f'Precision: {precision_score(y_test, y_pred_cart_camel, average=\"weighted\"):.2f}, Recall: {recall_score(y_test, y_pred_cart_camel, average=\"weighted\"):.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":370,"status":"ok","timestamp":1686037854294,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"VDgcH5Gqr-lY","outputId":"0b241787-ceed-46d6-b5fa-5188d8f23e7c"},"outputs":[],"source":["from sklearn.tree import export_text\n","\n","tree_rules = export_text(decisionTreeModel, feature_names=list(X_train.columns))\n","\n","print(tree_rules)"]},{"cell_type":"markdown","metadata":{"id":"7MVBQ4jOFtjv"},"source":["# Training a more opaque classifier - Random Forest\n","\n","In this example we train a model that does not provide the possibility to look into the decision process - it is more opaque. "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":409,"status":"ok","timestamp":1686044751814,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"z64BqJQ3F25U"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","randomForestModel = RandomForestClassifier()\n","randomForestModel.fit(X_train, y_train)\n","y_pred_rf = randomForestModel.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1686044784073,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"aH2e2gC1GW8y","outputId":"0925e077-fa81-433b-e3f1-4300663e2099"},"outputs":[],"source":["# now, let's evaluate the code\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","\n","print(f'Accuracy: {accuracy_score(y_test, y_pred_rf):.2f}')\n","print(f'Precision: {precision_score(y_test, y_pred_rf, average=\"weighted\"):.2f}, Recall: {recall_score(y_test, y_pred_rf, average=\"weighted\"):.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":359,"status":"ok","timestamp":1686045000183,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"Hd3wG9cAG9WF","outputId":"5b9f0e13-2c61-44b4-fa70-d46c1f7300df"},"outputs":[],"source":["# now, let's check which of the features are the most important ones\n","# first we create a dataframe from this list\n","# then we sort it descending\n","# and then filter the ones that are not imporatnt\n","dfImportantFeatures = pd.DataFrame(randomForestModel.feature_importances_, index=X.columns, columns=['importance'])\n","\n","# sorting values according to their importance\n","dfImportantFeatures.sort_values(by=['importance'], \n","                                ascending=False, \n","                                inplace=True)\n","\n","# choosing only the ones that are important, skipping\n","# the features which have importance of 0\n","dfOnlyImportant = dfImportantFeatures[dfImportantFeatures['importance'] != 0]\n","\n","# print the results\n","print(f'All features: {dfImportantFeatures.shape[0]}, but only {dfOnlyImportant.shape[0]} are used in predictions. ')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1629,"status":"ok","timestamp":1686045041699,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"pS9faqVJHUdA","outputId":"e5a83ac2-8f09-4f45-97f2-028e918e0971"},"outputs":[],"source":["# we use matplotlib and seaborn to make the plot\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Define size of bar plot\n","# We make the x axis quite much larger than the y-axis since\n","# there is a lot of features to visualize\n","plt.figure(figsize=(40,10))\n","\n","# plot Searborn bar chart\n","# we just use the blue color\n","sns.barplot(y=dfOnlyImportant['importance'], \n","            x=dfOnlyImportant.index, \n","            color='steelblue')\n","\n","# we make the x-labels rotated so that we can fit\n","# all the features\n","plt.xticks(rotation=90)\n","\n","sns.set(font_scale=6)\n","\n","# add chart labels\n","plt.title('Importance of features, in descending order')\n","plt.xlabel('Feature importance')\n","plt.ylabel('Feature names')"]},{"cell_type":"markdown","metadata":{"id":"0aB2x9A0JYxA"},"source":["# Neural networks\n","\n","The demo below shows how we can use neural networks in PyTorch to achieve the same results - training on the Camel data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87286,"status":"ok","timestamp":1686045800958,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"YffSgTewJhhh","outputId":"f4fcc8b9-2c52-4353-9b2d-1855ef19515f"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Define the neural network architecture\n","class NeuralNetwork(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNetwork, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, num_classes)\n","    \n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        return out\n","\n","# Define the hyperparameters\n","input_size = X_train.shape[1]  # Number of input features\n","hidden_size = 64              # Number of neurons in the hidden layer\n","num_classes = 2               # Number of output classes\n","\n","# Create an instance of the neural network\n","model = NeuralNetwork(input_size, hidden_size, num_classes)\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Convert the data to PyTorch tensors\n","X_train_tensor = torch.Tensor(X_train.values)\n","y_train_tensor = torch.LongTensor(y_train.values)\n","X_test_tensor = torch.Tensor(X_test.values)\n","\n","# Training the neural network\n","num_epochs = 10000\n","batch_size = 32\n","for epoch in range(num_epochs):\n","    for i in range(0, len(X_train_tensor), batch_size):\n","        batch_X = X_train_tensor[i:i+batch_size]\n","        batch_y = y_train_tensor[i:i+batch_size]\n","\n","        # Forward pass\n","        outputs = model(batch_X)\n","        loss = criterion(outputs, batch_y)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Print the loss at the end of each epoch\n","    if (epoch % 100 == 0):\n","      print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.3f}\")\n","\n","# Testing the neural network\n","with torch.no_grad():\n","    outputs = model(X_test_tensor)\n","    _, predicted = torch.max(outputs.data, 1)\n","    y_pred_nn = predicted.numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":346,"status":"ok","timestamp":1686045902533,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"ZpOcXadzKMF8"},"outputs":[],"source":["with torch.no_grad():\n","    model.eval()  # Set the model to evaluation mode\n","    X_test_tensor = torch.Tensor(X_test.values)\n","    outputs = model(X_test_tensor)\n","    _, predicted = torch.max(outputs.data, 1)\n","    y_pred_nn = predicted.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":359,"status":"ok","timestamp":1686045921483,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"9mZu1vuoKKK9","outputId":"b2bdf619-c5f5-4f86-fa93-a17753371b52"},"outputs":[],"source":["# now, let's evaluate the code\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","\n","print(f'Accuracy: {accuracy_score(y_test, y_pred_nn):.2f}')\n","print(f'Precision: {precision_score(y_test, y_pred_nn, average=\"weighted\"):.2f}, Recall: {recall_score(y_test, y_pred_nn, average=\"weighted\"):.2f}')"]},{"cell_type":"markdown","metadata":{"id":"rGW5HDH3QiXO"},"source":["# Data leak\n","\n","The following code illustrates a mistake when we use parts of the same data to both train and test the model. This problem is called the data leak problem, as we have the same data leaking from training to validation."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":337,"status":"ok","timestamp":1686047576511,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"7Hwz3RNIQvah"},"outputs":[],"source":["# first, we need to prepare the data that can leak\n","# for this, we use the split function with different parameters\n","# we use 20% of the data to test the model\n","# which means that at least 10% of the data is the same as in the training set\n","X_trainL, X_testL, y_trainL, y_testL = \\\n","        sklearn.model_selection.train_test_split(X, y, random_state=42, train_size=0.8)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":391,"status":"ok","timestamp":1686047607396,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"vIf39420RFsV"},"outputs":[],"source":["# now, let's evaluate the model on this new data\n","with torch.no_grad():\n","    model.eval()  # Set the model to evaluation mode\n","    X_test_tensor = torch.Tensor(X_testL.values)\n","    outputs = model(X_test_tensor)\n","    _, predicted = torch.max(outputs.data, 1)\n","    y_pred_nn = predicted.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":380,"status":"ok","timestamp":1686047634701,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"-bKByzq5ROdb","outputId":"4bd83d77-114d-4cd6-beb0-a131344d23f0"},"outputs":[],"source":["# now, let's evaluate the code\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","\n","print(f'Accuracy: {accuracy_score(y_testL, y_pred_nn):.2f}')\n","print(f'Precision: {precision_score(y_testL, y_pred_nn, average=\"weighted\"):.2f}, Recall: {recall_score(y_testL, y_pred_nn, average=\"weighted\"):.2f}')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMwxYJ2skUkXVJs4xdZglYE","mount_file_id":"1Wt-R1lyxpbFfoiA8F4_2y7UCN3RybkZS","provenance":[{"file_id":"1Kvl9mEqrzhcpgDFqH0h4RsU8gd3rVyaO","timestamp":1686035707151}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
