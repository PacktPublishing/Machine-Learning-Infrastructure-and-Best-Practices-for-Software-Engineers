{"cells":[{"cell_type":"markdown","metadata":{"id":"IfX_JqnmRot-"},"source":["# Word embeddings\n","\n","This workbook demonstrates how to use word embeddings as a feature extraction technique. It uses the implementation of the word embedding algorithm from gensim package. \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p0cCMNEVSKhv"},"outputs":[],"source":["!pip install -q gensim\n"]},{"cell_type":"code","execution_count":75,"metadata":{"executionInfo":{"elapsed":233,"status":"ok","timestamp":1683477835354,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"7zV0DzTZRljQ"},"outputs":[],"source":["from gensim.models import word2vec"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1683472497389,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"_q8_6VCcSnpi","outputId":"e63e30f7-33de-4b3d-947f-f7b5f8966da3"},"outputs":[{"name":"stdout","output_type":"stream","text":["The file (and thus our corpus) contains 184 lines\n"]}],"source":["# now, we need to prepare a dataset\n","# in our case, let's just read a dataset that is a code of a program\n","\n","# in this example, I use the file from an open source component - Azure NetX\n","# the actual part is not that important, as long as we have a set of \n","# tokens that we want to analyze\n","path = './nx_icmp_checksum_compute.c'\n","\n","# read all lines into an array\n","with open(path, 'r') as r:\n","  lines = r.readlines()\n","\n","# and see how many lines we got\n","print(f'The file (and thus our corpus) contains {len(lines)} lines')"]},{"cell_type":"code","execution_count":76,"metadata":{"executionInfo":{"elapsed":291,"status":"ok","timestamp":1683477841647,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"BvfHsTH4SsiH"},"outputs":[],"source":["# we need to pass splitted sentences to the model\n","tokenized_sentences = [sentence.split() for sentence in lines]\n","\n","model = word2vec.Word2Vec(tokenized_sentences, \n","                          vector_size=10, \n","                          window=1, \n","                          min_count=0, \n","                          workers=4)"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1683477843938,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"p27rFfnNTCrj","outputId":"bfcc4a59-05ef-466e-fa53-2eab12416f70"},"outputs":[{"data":{"text/plain":["{'*/': 0,\n"," '/*': 1,\n"," 'the': 2,\n"," '=': 3,\n"," 'checksum': 4,\n"," '->': 5,\n"," 'packet': 6,\n"," 'if': 7,\n"," 'of': 8,\n"," '/**************************************************************************/': 9,\n"," '}': 10,\n"," '{': 11,\n"," '+': 12,\n"," 'checksum.': 13,\n"," 'to': 14,\n"," 'word_ptr': 15,\n"," 'length': 16,\n"," 'in': 17,\n"," 'a': 18,\n"," '/**': 19,\n"," 'at': 20,\n"," 'and': 21,\n"," 'ULONG': 22,\n"," 'is': 23,\n"," 'Determine': 24,\n"," 'byte': 25,\n"," 'into': 26,\n"," '(checksum': 27,\n"," '&': 28,\n"," 'word': 29,\n"," 'Microsoft': 30,\n"," 'Add': 31,\n"," 'ICMP': 32,\n"," 'pointer.': 33,\n"," 'current_packet': 34,\n"," 'Setup': 35,\n"," '0;': 36,\n"," 'nx_packet_append_ptr)': 37,\n"," 'we': 38,\n"," 'word.': 39,\n"," '>>': 40,\n"," 'packet.': 41,\n"," 'NX_LOWER_16_MASK);': 42,\n"," 'Move': 43,\n"," 'pointer': 44,\n"," 'Yuxin': 45,\n"," '-': 46,\n"," '(UCHAR': 47,\n"," 'current': 48,\n"," '>=': 49,\n"," 'else': 50,\n"," 'end': 51,\n"," '#include': 52,\n"," 'nx_packet_prepend_ptr;': 53,\n"," 'RELEASE': 54,\n"," 'None': 55,\n"," 'zero': 56,\n"," 'short_temp;': 57,\n"," 'nx_packet_last)': 58,\n"," 'there': 59,\n"," '6.1': 60,\n"," 'packet_ptr': 61,\n"," 'Pickup': 62,\n"," 'We': 63,\n"," 'DESCRIPTION': 64,\n"," 'sizeof(USHORT))': 65,\n"," 'add': 66,\n"," 'need': 67,\n"," 'have': 68,\n"," 'Zhou': 69,\n"," '*)current_packet': 70,\n"," 'upper': 71,\n"," 'NX_SHIFT_BY_16)': 72,\n"," 'endian': 73,\n"," '(long_temp': 74,\n"," 'swap': 75,\n"," 'will': 76,\n"," 'This': 77,\n"," 'macros': 78,\n"," 'these': 79,\n"," 'specified,': 80,\n"," 'NX_LITTLE_ENDIAN': 81,\n"," 'If': 82,\n"," 'decrease': 83,\n"," 'logic.': 84,\n"," '16-bits': 85,\n"," 'sizeof(ULONG);': 86,\n"," '16-bit': 87,\n"," 'sizeof(USHORT);': 88,\n"," '*)word_ptr);': 89,\n"," 'Endian': 90,\n"," 'length.': 91,\n"," 'next': 92,\n"," 'swapping': 93,\n"," 'Azure': 94,\n"," 'License': 95,\n"," 'from': 96,\n"," 'Software': 97,\n"," 'supplied': 98,\n"," 'license': 99,\n"," 'text': 100,\n"," 'Full': 101,\n"," 'Terms': 102,\n"," 'RTOS.': 103,\n"," 'for': 104,\n"," 'directory': 105,\n"," 'under': 106,\n"," 'CALLS': 107,\n"," '05-19-2020': 108,\n"," 'NAME': 109,\n"," 'DATE': 110,\n"," 'HISTORY': 111,\n"," 'routines': 112,\n"," 'BY': 113,\n"," 'Copyright': 114,\n"," 'CALLED': 115,\n"," '(c)': 116,\n"," 'licensed': 117,\n"," 'Corporation.': 118,\n"," 'All': 119,\n"," 'rights': 120,\n"," 'OUTPUT': 121,\n"," 'reserved.': 122,\n"," 'can': 123,\n"," 'software': 124,\n"," 'INPUT': 125,\n"," 'Pointer': 126,\n"," 'AUTHOR': 127,\n"," 'be': 128,\n"," 'computes': 129,\n"," 'files.': 130,\n"," 'system': 131,\n"," 'necessary': 132,\n"," 'Include': 133,\n"," 'NX_SOURCE_CODE': 134,\n"," '#define': 135,\n"," '(ICMP)': 136,\n"," 'Initial': 137,\n"," 'Message': 138,\n"," 'Control': 139,\n"," 'Internet': 140,\n"," 'Component': 141,\n"," 'NetX': 142,\n"," 'software.': 143,\n"," 'root': 144,\n"," '\"nx_api.h\"': 145,\n"," '\"nx_icmp.h\"': 146,\n"," '#if': 147,\n"," 'C': 148,\n"," 'function': 149,\n"," 'found': 150,\n"," 'Corporation': 151,\n"," 'LICENSE': 152,\n"," 'Zhou,': 153,\n"," 'this': 154,\n"," 'PORTABLE': 155,\n"," '(!defined(NX_DISABLE_ICMP_TX_CHECKSUM)': 156,\n"," '_nx_icmp_checksum_compute': 157,\n"," 'file': 158,\n"," 'FUNCTION': 159,\n"," '!defined(NX_DISABLE_ICMP_RX_CHECKSUM))': 160,\n"," 'https://aka.ms/AzureRTOS_EULA': 161,\n"," '||': 162,\n"," 'Protocol': 163,\n"," '#endif': 164,\n"," 'Version': 165,\n"," '*((ULONG': 166,\n"," '&&': 167,\n"," '((word_ptr': 168,\n"," 'are': 169,\n"," 'NX_CHANGE_USHORT_ENDIAN(short_temp);': 170,\n"," '*((USHORT': 171,\n"," 'short_temp': 172,\n"," 'lower': 173,\n"," 'NX_SHIFT_BY_16);': 174,\n"," 'NX_CHANGE_ULONG_ENDIAN(long_temp);': 175,\n"," 'long_temp': 176,\n"," 'nx_packet_next))': 177,\n"," 'ULONG.': 178,\n"," 'whole': 179,\n"," 'sizeof(ULONG))': 180,\n"," 'word_ptr)': 181,\n"," 'nx_packet_append_ptr': 182,\n"," '((UINT)(current_packet': 183,\n"," 'left.': 184,\n"," 'one': 185,\n"," 'least': 186,\n"," '(current_packet': 187,\n"," 'crossed': 188,\n"," '6.0': 189,\n"," 'operation': 190,\n"," 'computed': 191,\n"," 'Return': 192,\n"," 'NX_LOWER_16_MASK;': 193,\n"," '16-bits.': 194,\n"," 'off': 195,\n"," 'Mask': 196,\n"," 'overflow.': 197,\n"," 'an': 198,\n"," 'generates': 199,\n"," 'previous': 200,\n"," 'boundary.': 201,\n"," 'case': 202,\n"," 'again': 203,\n"," 'it': 204,\n"," 'Do': 205,\n"," 'bits': 206,\n"," 'carry': 207,\n"," 'new': 208,\n"," 'nx_packet_next;': 209,\n"," 'structure.': 210,\n"," '(length)': 211,\n"," 'while': 212,\n"," \"packet's\": 213,\n"," 'UCHAR': 214,\n"," '*': 215,\n"," '/': 216,\n"," 'return(checksum);': 217,\n"," 'byte.': 218,\n"," 'padding': 219,\n"," 'nx_packet_length;': 220,\n"," '*current_packet;': 221,\n"," 'NX_PACKET': 222,\n"," '*word_ptr;': 223,\n"," 'length;': 224,\n"," 'calculate': 225,\n"," 'USHORT': 226,\n"," 'long_temp;': 227,\n"," '*packet_ptr)': 228,\n"," '_nx_icmp_checksum_compute(NX_PACKET': 229,\n"," 'version': 230,\n"," 'resulting': 231,\n"," 'comment(s),': 232,\n"," 'Modified': 233,\n"," '09-30-2020': 234,\n"," '!=': 235,\n"," 'length)': 236,\n"," 'single': 237,\n"," 'alignment': 238,\n"," 'Loop': 239,\n"," 'packet_ptr;': 240,\n"," 'input': 241,\n"," 'Initialize': 242,\n"," '*)packet_ptr': 243,\n"," 'start': 244,\n"," '*(packet_ptr': 245,\n"," 'only': 246,\n"," 'first': 247,\n"," 'Write': 248,\n"," '*((packet_ptr': 249,\n"," 'end.': 250,\n"," 'message,': 251,\n"," 'Multi-packet': 252,\n"," '(packet_ptr': 253,\n"," 'last': 254,\n"," 'length++;': 255,\n"," 'alignment.': 256,\n"," 'two': 257,\n"," '(((length': 258}"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["# now, let's see the vocabulary of the model\n","model.wv.key_to_index"]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":222,"status":"ok","timestamp":1683477993318,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"hZtuJyKZG0M_","outputId":"4cf01f6f-7039-4ad2-f28d-fe346a51f3dc"},"outputs":[{"data":{"text/plain":["[('NX_LOWER_16_MASK;', 0.8372778296470642),\n"," ('Mask', 0.8019374012947083),\n"," ('DESCRIPTION', 0.7171915173530579),\n"," ('Version', 0.7050908803939819),\n"," ('Pickup', 0.6866066455841064),\n"," ('are', 0.6395519971847534),\n"," ('Do', 0.6153941750526428),\n"," ('BY', 0.6148180365562439),\n"," ('NX_LITTLE_ENDIAN', 0.5829669833183289),\n"," ('under', 0.5750270485877991)]"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["model.wv.most_similar(positive=['add'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1683473949487,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"jZTA2ADQ0Tpl","outputId":"9ee686a3-d9db-4256-97b8-da5d60871e98"},"outputs":[{"data":{"text/plain":["[('again', 0.24998697638511658),\n"," ('word', 0.21356187760829926),\n"," ('05-19-2020', 0.21174617111682892),\n"," ('*current_packet;', 0.2079058289527893),\n"," ('current_packet', 0.2042725533246994),\n"," ('short_temp', 0.1908235102891922),\n"," ('NX_SHIFT_BY_16)', 0.18824389576911926),\n"," ('packet.', 0.18712595105171204),\n"," ('length;', 0.18539084494113922),\n"," ('computed', 0.18160541355609894)]"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["# since this is not a tokenizer, we cannot use it to tokenize our simple C program\n","# but we can do other things, like finding the similar words\n","\n","# in the below statement, we mean something like:\n","# file + function - found = similar\n","similar = model.wv.most_similar(positive=['file', 'function'], negative=['found'])\n","\n","similar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRvJZKgo1HJ-"},"outputs":[],"source":["# if we want to use our C program, we need to use it in the training data,\n","# otherwise we get an exeption like this:\n","\n","# and check the similar words to \"return\"\n","similar = model.wv.most_similar(positive=['return'])\n","\n","similar "]},{"cell_type":"markdown","metadata":{"id":"EzwoYHfj5PRw"},"source":["## FastText\n","\n","To address the problem of words that do not exist, we can use the FastText model instead, which is able to guess the words that do not exist"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1683474569244,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"obk5VQQt5a0B","outputId":"0769f15b-5e0c-4380-ad0c-2e8b59325c10"},"outputs":[{"data":{"text/plain":["(16, 130)"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["from gensim.models import FastText\n","\n","# create the instance of the model\n","model = FastText(vector_size=4, \n","                 window=3, \n","                 min_count=1)\n","\n","# build a vocabulary\n","model.build_vocab(corpus_iterable=tokenized_sentences)\n","\n","# and train the model\n","model.train(corpus_iterable=tokenized_sentences, \n","            total_examples=len(tokenized_sentences), \n","            epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":397,"status":"ok","timestamp":1683474648752,"user":{"displayName":"Miroslaw Staron","userId":"03361447941535209117"},"user_tz":-120},"id":"8HMTLmjo6Csi","outputId":"9fdc49ad-af1b-4125-8b96-04b702ffe89d"},"outputs":[{"data":{"text/plain":["[('void', 0.5913326740264893),\n"," ('int', 0.43626993894577026),\n"," ('{', 0.2602742612361908),\n"," ('\"Hello', 0.23500549793243408),\n"," ('}', 0.21387670934200287),\n"," ('argc,', 0.1757005751132965),\n"," ('World', 0.17528733611106873),\n"," ('\");', 0.15775901079177856),\n"," ('0;', 0.1009957417845726),\n"," ('**argc)', -0.29264017939567566)]"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["# now, let's try to use the word that is not in the vocabulary\n","similar = model.wv.most_similar(positive=['return'])\n","\n","# and voila, here it is, the model can approximate \n","# the words that are not part of the vocabulary\n","similar"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPZ6r4R6JfD+rAJOOJw1T/h","mount_file_id":"1ZkksUalwTFoHAPqeAT-bwmDs1sccx6lx","provenance":[{"file_id":"1fS4wUfhuvyYurWEqYQoCUwYEhJoUwwBz","timestamp":1683471727034}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
